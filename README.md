# 学习路径

这是我的学习路径（因为之前会使用 Python 所以对于 Python 的基本语法内容并不包含在内），大家可以参考：

## 了解深度学习的概念

观看系列视频：[飞天侠客：从函数到神经网络](https://www.bilibili.com/video/BV1uGA3eLEeu)

了解了基本的神经网络术语与基本的网络模型，推荐观看，讲的很不错，评价给到 **顶级**。

## 学习 MLP 网络

感觉自己可以了，于是就想要先学学简单的网络，完成简单的分类问题，于是看了杰哥的视频：[杰哥：PyTorch深度学习：深度神经网络（DNN）](https://www.bilibili.com/video/BV1Z8411R7PH)

杰哥的视频主要是对着讲义讲的，所有代码都是我跟着讲义打出来的，我学习的笔记请看： 1~7 节的 Jupyter 笔记本，
杰哥的视频中貌似把 MLP 标记为了 DNN ，DNN 根据查询资料是深度神经网络的意思，是所有神经网络的统称，应该叫
多层感知器 （MLP）合理一点。

由于视频全是对着讲义讲的，没有代码实操，评价给到 **人上人** ，适合先照葫芦画瓢，一步一步先熟悉 Pytorch 。
并且了解 LeNet 、 AlexNet 、 GoogLeNet 、 ResNet 等经典神经网络。

## 读经典论文 AlexNet

跟着打代码打了一段时间之后，不免会出现很多问题，比如：视频中介绍的这么多网络为什么他们的架构可行？
换句话说，为什么中间的某个隐藏层一定是 128 最有效果，我再大一点不行吗？小一点不行吗？
看看前人的研究是否能给我带来启发，于是去读论文，读论文可以跟着 [李沐老师：AlexNet论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1hq4y157t1/)
一起阅读。

视频评价给到 **顶级** ，不仅教你怎么读论文，还告诉你怎样写论文更好，我批注过的论文可以查看第 8 节的文件。

## 回看工程基础

经过上面的学习，已经掌握了一些基本的术语与一些基本的概念，对于神经网络的发展也大概有了了解，现在可以看看数学上的内容。

如何切实的体会到神经网络，如何“摸到”神经网络，我们要研究更加本质的东西！于是推荐观看：参考唐一旦老师的视频：

[唐一旦老师：《徒手实现最优化算法--人工智能的工程基础](https://www.bilibili.com/video/BV1Ft421K7NH)

我学习的笔记请参考：9~10 节的 Jupyter 笔记本，里面有我自己的部分愚见

# 神经网络的概念建立

下面的内容都是从学习过程中 COPY 出来的，方便定位和查漏补缺。

### [飞天侠客：从函数到神经网络](https://www.bilibili.com/video/BV1uGA3eLEeu)

飞天侠客老师的视频用白话文讲述了神经网络的本质，推荐看完他的全系列合集视频，这可以让我们初步构建神经网络的总体框架，
为之后的学习奠基。

此外，系列视频中还讲述了最几年的主流人工智能流派，如果你是萌新，推荐入坑。

视频之后的合集中还会简单介绍激活函数、向前传播、反向传播的一些基本概念，为后续神经网络的 MLP、CNN、RNN 等网络的学习有初步的印象。

### [唐一旦老师：《徒手实现多层感知器--经典模型的启示录](https://www.bilibili.com/video/BV1LT421v7Lw?t=84.9)
    
这个视频也是将神经网络的基本概念的，不过更多的是聚焦于数学上的实现，唐一旦老师的视频更多的是带着大家实践，并且手把手讲清楚
每一个基本原理，非常适合边看边学，适合自学。

# 基本编程手法

编程需要用到 Pytorch 可以在以下几个老师的视频中学习：

#### [杰哥：PyTorch深度学习：深度神经网络（DNN）](https://www.bilibili.com/video/BV1Z8411R7PH)

推荐看节选的一小部分：00:00 ~ 04:10，简单介绍了一下张量，如何转化、如何生成等。

#### [唐一旦老师：《Pytorch 编程基础》](https://www.bilibili.com/video/BV1Ft421K7NH?t=2050.7)

推荐看节选的一小部分：34:16 ~ 结尾，介绍了 Pytorch 的基本用法：张量、广播机制等，讲的很细。


# 配套教材仓库

- [杰哥：PyTorch深度学习网盘资料](https://pan.baidu.com/s/1aiuxsNigprcknBHEc7U0pw?pwd=2828)
- [唐一旦老师：《解构大语言模型：从线性回归到通用人工智能》配套代码](https://github.com/GenTang/regression2chatgpt/tree/zh)